#### binning ####

## binning is probably the most complicated thing 
## we will do. We need to conduct parallel 
## pipelines with three binning software,
## and combine the results for the bin refining
## step with DAS tools. 

## let's make a directory:

mkdir /vol/funMicStorage/zymoAnalysis/binning

cd /vol/funMicStorage/zymoAnalysis/binning

## first step - map our contigs back to our raw reads


## in this step, we are trying to find out how often
## contigs are found in the metagenome reads. This
## step gives us a kind of abundance information about
## each of our contigs. Theoretically, contigs that 
## appear in approx. equal amounts are more likely to 
## belong to the same genome. 

## we'll use bbmap software for this mapping step:

#conda deactivate
conda activate RawReadProcessing

mkdir coverage

cd coverage 
## or 
cd /vol/funMicStorage/zymoAnalysis/binning/coverage

assembly=/vol/funMicStorage/zymoAnalysis/assembly/megahit_out/final.contigs.fa
fast1=/vol/funMicStorage/datasets/zymo/ERR7255689_1.fastq.gz
fast2=/vol/funMicStorage/datasets/zymo/ERR7255689_2.fastq.gz
nohup bbmap.sh \
   threads=13 \
   minid=.97 \
   idfilter=.95 \
   ref=$assembly \
   in=$fast1 \
   in2=$fast2 \
   outm=rawReads_to_assembly.sam \
   bamscript=rawReads_to_assembly_to_bam.sh &

## this generates a sequence alignment map (SAM) file

## this is a really common file format in bioinformatics
## you can look at it:

less rawReads_to_assembly.sam

## SAMs are big. They can be compressed to a binary form
## without any loss of information. Also, we need to 
## sort and index (make a "map") of all these alignments,
## to make the coverage files.

## our bbmap program made us a custom script to do all 
## this:

bash rawReads_to_assembly_to_bam.sh

## now that we have mapped our reads back to our assembly,
## we can use this information to generate coverage tables
## for downstream binning programs. 

## generate coverage table ##

## for all of 3 of the binning programs,
## we need a coverage table. We'll use a custom script 
## from JGI, that comes with metabat2. Because of this,
## we change the conda environment:

#conda deactivate
conda activate binning 

## let's stay in our "coverage directory", because these
## files should be useful to all of 3 of our binning programs:

cd /vol/funMicStorage/zymoAnalysis/binning/coverage

assembly=/vol/funMicStorage/zymoAnalysis/assembly/megahit_out/final.contigs.fa
sortedBAM=/vol/funMicStorage/zymoAnalysis/binning/coverage/rawReads_to_assembly_sorted.bam

jgi_summarize_bam_contig_depths \
    --outputDepth coverage_Depths.txt \
    --referenceFasta  $assembly \
    $sortedBAM

## this generates a coverage table. But we have to 
## reformat it a bit to fit the needs of the binning programs. 
## the contig names are too complex. Trim them down.

## use the "cut/paste" programs to fix it. 
cut $coverageTable -f1 | cut -d" " -f1 > contigName.txt
cut $coverageTable --complement -f1 > everythingElse.txt
paste contigName.txt everythingElse.txt > simpleNames.txt
## If you are curious about cut/paste, ask me about it.

## rename files
mv coverage_Depths.txt coverage_Depths.txt.bk
mv simpleNames.txt coverage_Depths.txt

## check it, does your new file look like mine?

head coverage_Depths.txt


### metabat2 ###

## the first binning software we will use is
## metabat2. It is the simplest to use.

#conda deactivate
conda activate binning 

mkdir /vol/funMicStorage/zymoAnalysis/binning/metabat

cd /vol/funMicStorage/zymoAnalysis/binning/metabat

assembly=/vol/funMicStorage/zymoAnalysis/assembly/megahit_out/final.contigs.fa
#coverageTable=/vol/funMicStorage/zymoAnalysis/binning/coverage/coverage_Depths.txt
coverageTable=/vol/funMicStorage/zymoAnalysis/binning/coverage/simpleNames.txt
metabat2 \
  -i $assembly \
  -a $coverageTable \
  -o "metabat" \
  -t 12


### VAMB ###

## another, newer assembler is VAMB. It uses complex machine
## learning algorithms but is still fundamentally based
## on 4mer (tetranucleotide) frequencies and coverage/abundance

#conda deactivate
conda activate binning 

mkdir /vol/funMicStorage/zymoAnalysis/binning/vamb

cd /vol/funMicStorage/zymoAnalysis/binning/vamb

assembly=/vol/funMicStorage/zymoAnalysis/assembly/megahit_out/final.contigs.fa
#coverageTable=/vol/funMicStorage/zymoAnalysis/binning/coverage/coverage_Depths.txt
coverageTable=/vol/funMicStorage/zymoAnalysis/binning/coverage/simpleNames.txt

nohup vamb \
    --fasta $assembly \
    --jgi $coverageTable \
    -t 64 \
    --minfasta 200000 \
    --outdir vambOut & 

## the -t flag lowers the batch size of contigs
## that are put into memory. We are lowering
## here because we have such a simple community.

\time nohup vamb --outdir vambOut \
  --fasta illumcatalogue.fna.gz \
  --bamfiles illumReadsAligned2Contigs.bam \
  -t 7 \
  -o C \
  --minfasta 200000 &> vambLog.txt &
