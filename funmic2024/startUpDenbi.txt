## let's set up our denbi pilot machine for 2024

ssh ubuntu@129.70.51.6 -p 30487

## let's add Dimitri:
## Dimitri ##

pwgen 1 10

EHLsVmmpXb

sudo adduser dimitri

sudo usermod -aG sudo dimitri

## made an ssh folder and authorized key file...

cd /home/dimitri

mkdir .ssh

cd .ssh
touch authorized_keys ## then paste in key

## I think these need to belong to him...
chown dimitri:dimitri .ssh
chown dimitri:dimitri authorized_keys 

## this VM is behaving really funny. 
## constantly checking the ssh connection, and kicking 
## us out when it does this.

## so we try a new machine.

ssh -i ~/.ssh ubuntu@129.70.51.6 -p 30476

## meh, that old VM is basically dead, can't connect

## seems to work ok. 

## need to mount the volume...

## following: https://simplevm.denbi.de/wiki/simple_vm/volumes/

lsblk ## vde, I think

lsblk -o NAME,SIZE,MOUNTPOINT,FSTYPE,TYPE | egrep -v "^loop"

blkid /dev/vde ## not in there?

## guess it is not yet formatted? 

#sudo mkfs.ext4 /dev/vde

sudo mkdir -p /vol/funMicStorage

sudo mount /dev/vde /vol/funMicStorage

## add it to the fstab

## get the UUID
lsblk -o NAME,SIZE,MOUNTPOINT,FSTYPE,TYPE,UUID | egrep -v "^loop"

## add line to fstab 
UUID=a29e2283-ddb8-477b-ae03-14d276642b7f       /vol/funMicStorage      auto    defaults        0       2
## check after shutting down, seems stable

## how many cores do we have?

lscpu -p ## looks like 14, one core/cpu

### we need to get conda going ###

wget https://repo.anaconda.com/archive/Anaconda3-2023.09-0-Linux-x86_64.sh

## works, but conda not being found, probably because I put it on the 
## volume, so add to bashrc path def

export PATH=/vol/funMicStorage/anaconda3/bin:$PATH

## seems to work. 

## also, since we are always on the volume, can we change this to our home
## directory?

## meh, maybe better to add an alias to get students quickly?

alias vol="cd /vol/funMicStorage"

#### preliminary data #####

## let's grab the zymogen mock community reads, as per last year:

cd /vol/funMicStorage/datasets/

nohup wget ftp://ftp.sra.ebi.ac.uk/vol1/fastq/ERR725/009/ERR7255689/ERR7255689_1.fastq.gz &
nohup wget ftp://ftp.sra.ebi.ac.uk/vol1/fastq/ERR725/009/ERR7255689/ERR7255689_2.fastq.gz &

## the dataset that Dmitri wants to use, kelp on beaches:
https://www.ncbi.nlm.nih.gov/bioproject/?term=PRJEB36085

## made an accession list. put in on denbi

## script:
#####################
#!/bin/bash

cd /vol/funMicStorage/datasets/kelp
for i in $(cat SraAccList.csv); do
  echo $i
  fastq-dump $i -O .
done
#####################

nohup sh sraDownload.sh &


##################

#### software installs ####

## let's start on the installs

## conda and mamba are working together now. 
## to get mamba's solver into conda,
## following this page: https://www.anaconda.com/blog/a-faster-conda-for-a-growing-community

conda update -n base conda
conda install -n base conda-libmamba-solver
conda config --set solver libmamba

## get bioconda channel
conda config --add channels defaults
conda config --add channels bioconda
conda config --add channels conda-forge

## first environment: raw read processing 
## Dimitri would like to use:
conda create -n RawReadProcessing -c bioconda trim-galore bbmap seqtk phyloflash
## I added seqtk

## phyloFlash needs a database:

conda activate RawReadProcessing

cd /vol/funMicStorage/databases/phyloFlash

phyloFlash.pl -check_env

## as per: http://hrgv.github.io/phyloFlash/

wget https://zenodo.org/record/7892522/files/138.1.tar.gz # 5.5 GB download
tar -xzf 138.1.tar.gz

phyloFlash.pl -dbhome /vol/funMicStorage/databases/phyloFlash/138.1 -lib TEST -CPUs 14 \
 -read1 ${CONDA_PREFIX}/lib/phyloFlash/test_files/test_F.fq.gz \
 -read2 ${CONDA_PREFIX}/lib/phyloFlash/test_files/test_R.fq.gz \
 -almosteverything

## next, assembler:
conda create -n assembly -c bioconda megahit

## let's add quast for assembly quality:
## quast seems to rely on old versions of 
## python, can't install it with our assembler,
## probably would cause problems with other
## newer software. Gets its own environment.

conda create -n quast -c bioconda quast

## check to make sure that didn't break our assembler

## binning and refining

conda create -n binning -c bioconda metabat2 vamb das_tool
## ran without errors...

## we also need the following, according to the vamb github repo:
conda activate binning
conda install -c pytorch pytorch torchvision cudatoolkit=10.2
## but we don't have GPUs, so not sure why we need cuda
## that did some weird downgrades...not a good sign...
## we also need minimap2, will this install in this env?
conda install -c bioconda minimap2
## and samtools...
conda install -c bioconda samtools
## and bowtie2, oh jeez...
conda install -c bioconda bowtie2
## remember to test these. Stuff in this environment is the most likely to fail.

## genome quality checks:

## following https://github.com/chklovski/CheckM2

conda create -n magQC -c bioconda checkm2
## get some weird typeError from tensorflow
## so do lots of other folks: https://github.com/chklovski/CheckM2/issues/82
conda remove -n magQC --all 

## according to one answer, you have to make sure python isn't too old/new
conda create -n magQC -c bioconda -c conda-forge checkm2 'python>=3.7, <3.9'

conda activate magQC
checkm2 -h

nohup checkm2 database --download --path /vol/funMicStorage/databases/checkm2 &

checkm2 testrun ## looks good

 
#################################################################
## denbi VM is misbehaving, they need to know what I have installed:
conda env list
conda list > allCondaPackages_FunMicVM.txt
conda activate RawReadProcessing
conda list >> allCondaPackages_FunMicVM.txt
conda deactivate
conda activate assembly          
conda list >> allCondaPackages_FunMicVM.txt
conda deactivate
conda binning           
conda list >> allCondaPackages_FunMicVM.txt
conda deactivate

## get it local.
file=/home/ubuntu/allCondaPackages_FunMicVM.txt
scp -i /home/daniel/.ssh -P 30487 -r ubuntu@129.70.51.6:$file .
#################################################################

## for now, back to installations:

## classify genomes with gtdbtk
## following: https://ecogenomics.github.io/GTDBTk/installing/bioconda.html

conda create -n gtdbtk -c conda-forge -c bioconda gtdbtk=2.1.1

## try their script for getting the db:
conda activate gtdbtk

nohup download-db.sh ## was cut off, but looks right


## annotations
Prodigal https://github.com/hyattpd/Prodigal
diamond https://github.com/bbuchfink/diamond
EggNOG mapper https://github.com/eggnogdb/eggnog-mapper
InterProScan https://github.com/ebi-pf-team/interproscan
Prokka https://github.com/tseemann/prokka

## try one big environment:

conda create -n annotation -c bioconda -c conda-forge prodigal diamond eggnog-mapper interproscan prokka

## databases and testing:

## eggnog:

conda activate annotation

export EGGNOG_DATA_DIR=/vol/funMicStorage/databases/eggnog-mapper-data/

## also EGGNOG_DATA_DIRneed to add that to bashrc?

echo $EGGNOG_DATA_DIR

## looks like. It's kind of complicated. Following:
https://docs.conda.io/projects/conda/en/latest/user-guide/tasks/manage-environments.html#macos-linux-save-env-variables

conda activate annotation; echo $CONDA_PREFIX

cd $CONDA_PREFIX

mkdir -p ./etc/conda/activate.d
mkdir -p ./etc/conda/deactivate.d
touch ./etc/conda/activate.d/env_vars.sh
touch ./etc/conda/deactivate.d/env_vars.sh

vim ./etc/conda/activate.d/env_vars.sh ## to say:

#############
#!/bin/sh


export EGGNOG_DATA_DIR=/vol/funMicStorage/databases/eggnog-mapper-data/
###############

vim ./etc/conda/deactivate.d/env_vars.sh

##############
#!/bin/sh

unset EGGNOG_DATA_DIR
##############

## I guess that's what it takes to redefine a conda environment-specific
## environmental variable every time...

## anyway, having set the variable...download eggnog databases
download_eggnog_data.py 

## test InterProScan install
./interproscan.sh ## runs without errors. Enough for now.

## test Prokka install
Prokka https://github.com/tseemann/prokka

prokka --listdb
## seems to work

#### tree visualization ####

## for arb, following:
http://vc.arb-home.de/readonly/trunk/arb_INSTALL.txt

wget --recursive \
  --no-parent -nH --cut-dirs=2 \
  http://download.arb-home.de/release/latest/

## I guess we really just need the ubuntu installation script
## there is none for ubuntu 22...try the one for ubuntu 20?
## apt doesn't have arb7, btw, just arb6

## let's try: arb-7.0.ubuntu2004-amd64.tgz 

sudo bash arb_install.sh

sudo bash /usr/arb/SH/arb_installubuntu4arb.sh arb

## according to this, add the following to .bashrc,
## for path update with ARB binary
######
ARBHOME=/usr/arb;export ARBHOME
LD_LIBRARY_PATH=${ARBHOME}/lib:${LD_LIBRARY_PATH}
export LD_LIBRARY_PATH
PATH=${ARBHOME}/bin:${PATH}
export PATH
######

ARB http://www.arb-home.de/downloads.html

## enable x11 forwarding in 

sudo vim /etc/ssh/ssh_config

## all the other instances will have to modified, when they come into being...
## actually, if we take a snapshot of this VM, we should be able to 
## avoid all the manual 

## set the following:
ForwardX11 yes
ForwardX11Trusted yes

## restart:
sudo systemctl restart sshd

## do we need set client (local) permissions?
## nope. runs well, just make sure to use the -X or -Y flag
## on the ssh command

conda create -n fasttree -c bioconda fasttree

conda activate fasttree


#### metabarcoding data and software ####

## our local file:
sipData=/home/daniel/Documents/teaching/functionalMicrobiomes/barcode2023/16S_amps_SIP_2022.zip
## put it here:
barcodeDir=/vol/funMicStorage/datasets/metabarcoding/
scp -i /home/daniel/.ssh -P 30487 -r $sipData ubuntu@129.70.51.6:$barcodeDir

## also get the new milan data from alfons:
file=/home/daniel/Documents/teaching/functionalMicrobiomes/barcode2023/Oemik-Exp014.zip
barcodeDir=/vol/funMicStorage/datasets/metabarcoding/
scp -i /home/daniel/.ssh -P 30487 -r $file ubuntu@129.70.51.6:$barcodeDir

## and his metadata
file=/home/daniel/Documents/teaching/functionalMicrobiomes/barcode2023/mapping.tsv
barcodeDir=/vol/funMicStorage/datasets/metabarcoding/
scp -i /home/daniel/.ssh -P 30487 -r $file ubuntu@129.70.51.6:$barcodeDir

## we need just milan's reads:

cd /vol/funMicStorage/datasets/metabarcoding/20230210_060720/Fastq

milanReadDir=/vol/funMicStorage/datasets/metabarcoding/milanReads
mv Oemik-001254* $milanReadDir
mv Oemik-001255* $milanReadDir
mv Oemik-001256* $milanReadDir
mv Oemik-001257* $milanReadDir
mv Oemik-001258* $milanReadDir
mv Oemik-001259* $milanReadDir
mv Oemik-001260* $milanReadDir
mv Oemik-001261* $milanReadDir
mv Oemik-001262* $milanReadDir 

## that's our data. now install Qiime: https://docs.qiime2.org/2023.9/install/native/

wget https://data.qiime2.org/distro/amplicon/qiime2-amplicon-2023.9-py38-linux-conda.yml
conda env create -n qiime2-amplicon-2023.9 --file qiime2-amplicon-2023.9-py38-linux-conda.yml
conda rename -n qiime2-amplicon-2023.9 qiime
conda activate qiime
qiime --help ## works for the moment

## I think we'll still need to get classifiers, silva etc
## we'll come back to this. 

########################################

#### trials with mc data #######


## how do they look?
## let's get the quality, think about trimming, and run phyloflash

conda activate RawReadProcessing

## our mc data from zymogen/sereika is here:
cd /vol/funMicStorage/datasets/zymo

mkdir /vol/funMicStorage/rawReadQC

outDir=/vol/funMicStorage/rawReadQC
file="ERR7255689_1.fastq.gz"
fastqc -t 10 \
  -o /vol/funMicStorage/rawReadQC \
  $file &> $outDir/$file"fastqcLog.txt" &

## and R2:
cd /vol/funMicStorage/datasets/zymo
outDir=/vol/funMicStorage/rawReadQC
file="ERR7255689_2.fastq.gz"
fastqc -t 10 \
  -o /vol/funMicStorage/rawReadQC \
  $file &> $outDir/$file"fastqcLog.txt" &

## get these locally:

getFile=/vol/funMicStorage/rawReadQC/ERR7255689_?_fastqc.html
putDir=/home/daniel/Documents/teaching/functionalMicrobiomes/readQC/zymoQC
scp -i /home/daniel/.ssh -P 30487 -r ubuntu@129.70.51.6:$getFile $putDir

## can these be viewed with x11 forwarding?

cd /vol/funMicStorage/rawReadQC

firefox ERR7255689_1_fastqc.html ## doesn't work for me. 

## possible solutions (that didn't work for me):
https://superuser.com/questions/310197/how-do-i-fix-a-cannot-open-display-error-when-opening-an-x-program-after-sshi
https://www.thegeekstuff.com/2010/06/xhost-cannot-open-display/

## for the moment, ARB works. Just download the other 
## files for firefox, etc:

##### phyloflash #####

## following: https://hrgv.github.io/phyloFlash/usage.html

conda activate RawReadProcessing

phyloFlash.pl -h

cd /vol/funMicStorage/phyloFlashOut
fast1=/vol/funMicStorage/datasets/zymo/ERR7255689_1.fastq.gz
fast2=/vol/funMicStorage/datasets/zymo/ERR7255689_2.fastq.gz
phyloDB=/vol/funMicStorage/databases/phyloFlash/138.1
\time phyloFlash.pl \
  -lib zymoPhyloFlashOut \
  -read1 $fast1 \
  -read2 $fast2 \
  -readlength 150 \
  -clusterid 98 \
  -taxlevel 7 \
  -dbhome $phyloDB \
  -CPUs 12 &> phyloflashlog.txt &

## took ~20 min, 17 gig RAM

getFile=/vol/funMicStorage/phyloFlashOut/
putDir=/home/daniel/Documents/teaching/functionalMicrobiomes/
scp -i /home/daniel/.ssh -P 30487 -r ubuntu@129.70.51.6:$getFile $putDir

####### assembly #####

conda activate assembly

mkdir -p /vol/funMicStorage/assemblies/zymoMC/

fast1=/vol/funMicStorage/datasets/zymo/ERR7255689_1.fastq.gz
fast2=/vol/funMicStorage/datasets/zymo/ERR7255689_2.fastq.gz
outdir=/vol/funMicStorage/assemblies/zymoMC/
\time -v megahit -1 $fast1 \
          -2 $fast2 \
          -t 12 \
          -o $outdir &> megahit.log &

## this takes ~50 min to complete, max use of ~6 gig RAM

## okay, let's look at it with quast

conda activate quast

mkdir /vol/funMicStorage/assemblyQC

cd /vol/funMicStorage/assemblyQC
zymoMCassembly=/vol/funMicStorage/assemblies/zymoMC/final.contigs.fa
zymoMCquastOut=/vol/funMicStorage/assemblyQC
## run the command
\time quast -t 12 \
  -o $zymoMCquastOut \
  $zymoMCassembly &> quastLog.txt &

less quastLog.txt
## trivial amount of time and memory used.

getFile=/vol/funMicStorage/assemblyQC/
putDir=/home/daniel/Documents/teaching/functionalMicrobiomes/quastOut/
scp -i /home/daniel/.ssh -P 30487 -r ubuntu@129.70.51.6:$getFile $putDir

cd /home/daniel/Documents/teaching/functionalMicrobiomes/quastOut/
## looks fine, n50 of ~100,000, if we don't filter anything
## pacbio says with long reads, your n50 should be over 1Mb, but whatever.
## https://www.pacb.com/blog/beyond-contiguity/

## for specifics on the quast stats: https://quast.sourceforge.net/docs/manual.html#sec3.3

####### binning ######

## let's try metabat on a couple different settings
## and VAMB on default

## VAMB ##

conda activate binning

mkdir /vol/funMicStorage/binning

cd /vol/funMicStorage/binning

## VAMB requires a different format for the alignment of
## read than we used above for metabat

mkdir -p zymo/vamb

cd /vol/funMicStorage/binning/zymo/vamb

## vamb has a custom script to start it off:
## define our variables
illuminaAssembly="/vol/funMicStorage/assemblies/zymoMC/final.contigs.fa"
reads1="/vol/funMicStorage/datasets/zymo/ERR7255689_1.fastq.gz"
reads2="/vol/funMicStorage/datasets/zymo/ERR7255689_2.fastq.gz"
concatenate.py illumcatalogue.fna.gz $illuminaAssembly

## they use different aligner, minimap2, so back to our alignment environment
## super quick, 1 min, no RAM needed

## make an index with minimap
minimap2 -d illumcatalogue.mmi illumcatalogue.fna.gz
## also quick, no RAM needed

## map our reads to metagenome assembly with minimap and samtools
## This takes some time, maybe 20 minutes

rm *bam; rm *tmp; rm *log

illuminaAssembly="/vol/funMicStorage/assemblies/zymoMC/final.contigs.fa"
reads1="/vol/funMicStorage/datasets/zymo/ERR7255689_1.fastq.gz"
reads2="/vol/funMicStorage/datasets/zymo/ERR7255689_2.fastq.gz"
minimap2 -t 14 -N 5 \
  -ax sr illumcatalogue.mmi \
  --split-prefix mmsplit $reads1 $reads2 |
samtools view -F 3584 \
  -b --threads 14 > illumReadsAligned2Contigs.bam 

## that is quick

## line 445 in last years script

## minimap does the alignments, outputs sam, pipes to samtools
## we use samtools to make a binary, 
## and get rid of some of the low quality reads and weird alignments
## explanation of samtool flags: https://broadinstitute.github.io/picard/explain-flags.html

## once we have our reads aligned to our metagenome assembly, run vamb itself

\time nohup vamb --outdir vambOut \
  --fasta illumcatalogue.fna.gz \
  --bamfiles illumReadsAligned2Contigs.bam \
  -t 7 \
  -o C \
  --minfasta 200000 &> vambLog.txt &

## -t 8 is for very simple communities, this number can be much higher
## --minfasta is bp, I thik

## finds nine bins, all over 2 million bp

#### onto metabat ####

conda deactivate

conda activate binning

## make our output directory

mkdir -p /vol/funMicStorage/binning/zymo/metabat
cd /vol/funMicStorage/binning/zymo/metabat

## we need to the reads back to the genome
## metabat documentation suggests bowtie, don't
## know why

mkdir /vol/funMicStorage/binning/zymo/metabat/readAlignmentsForBinning

illuminaAssembly="/vol/funMicStorage/assemblies/zymoMC/final.contigs.fa"
reads1="/vol/funMicStorage/datasets/zymo/ERR7255689_1.fastq.gz"
reads2="/vol/funMicStorage/datasets/zymo/ERR7255689_2.fastq.gz"
outdir="/vol/funMicStorage/binning/zymo/metabat/readAlignmentsForBinning"

## for our alignments we use bowtie, which needs an index of our assembly
## we could probably use another mapper (bbmap? minimap?), if we have
## time to tweak the scripts.

\time bowtie2-build $illuminaAssembly $outdir/zymoIlluminaAssembly
## ~5 minutes?

## do the alignment. 
\time nohup bowtie2 \
  -x $outdir/zymoIlluminaAssembly \
  -1 $reads1 -2 $reads2 \
  -S rawReads2Contigs.sam \
  --threads 7 \
  --local &

## started ~11:50

## This takes a long time, an hour with 7 cores. Use all cores
## and maybe we can find a better solution

## not run ## 

## sort it

3880489415

samtools sort -l 1 \
    -@14 \
    -o rawReads2ContigsSorted.bam \
    -O BAM \
    rawReads2Contigs.sam &

## to test, can we use the minimap-created alignment
## from above? if we sort it, it should be basically 
## the same...

minimapRead2Contigs=/vol/funMicStorage/binning/zymo/vamb/illumReadsAligned2Contigs.bam
samtools sort -l 1 \
    -@5 \
    -o minimapRawReads2ContigsSorted.bam \
    -O BAM \
    $minimapRead2Contigs
## pretty quick, ~5 min?

samtools view -h -o minimapRawReads2ContigsSorted.sam minimapRawReads2ContigsSorted.bam 

## now try actual binning with metabat2
## with both:

cd /vol/funMicStorage/binning/zymo/metabat

## first try with the minimap bam
## define our variables

illuminaAssembly="/vol/funMicStorage/assemblies/zymoMC/final.contigs.fa"
bam="readAlignmentsForBinning/minimapRawReads2ContigsSorted.bam"
runMetaBat.sh $illuminaAssembly $bam
## error, some sort of mismatch in the headers

## okay, didn't work. try with the minimap bam
## define our variables
illuminaAssembly="/vol/funMicStorage/assemblies/zymoMC/final.contigs.fa"
bam="readAlignmentsForBinning/rawReads2ContigsSorted.bam"

\time nohup runMetaBat.sh $illuminaAssembly $bam

which runMetaBat.sh

## two minutes, didn't seem to use much memory

#### metabat, different settings ####

## let's try some non-default settings, and use these in our 
## bin refinement process

less /vol/funMicStorage/anaconda3/envs/binning/bin/runMetaBat.sh

nohup runMetaBat.sh $illuminaAssembly $bam \
  --verysensitive \
  -p \
  -m 500 \
