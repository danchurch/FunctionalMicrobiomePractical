## okay, starting the setup for the funmic practical, spring 2025

## synch up our desktop computer with github:

https://github.com/danchurch/FunctionalMicrobiomePractical.git

git remote add origin https://github.com/danchurch/FunctionalMicrobiomePractical.git
git branch -M main
git remote set-url origin git@github.com:danchurch/FunctionalMicrobiomePractical.git
git push -u origin main

## our setup instance is here:

ssh ubuntu@129.70.51.6 -p 30423

## oops. Wrong key. do we have the denbi key on this work computer?
## this is probably a key on my laptop....

## I had to add a public key from desktop, via the notebook.
## let's do the same for dimitri, using the key he gave me last year.

## for conda, I think Dimitri and I need to share a user on this computer. 
## will just need to add his key. 

## now, is the volume already mounted?

lsblk

## mounted for the moment, 

lsblk -o NAME,SIZE,MOUNTPOINT,FSTYPE,TYPE  ##vdc


## change to user, not root
sudo chown ubuntu:ubuntu /vol/funmic

## if we restart the machine, do we lose the volume?:

## yup. 


## need the uuid, either with:
blkid /dev/vdc

## or 
lsblk -o NAME,SIZE,MOUNTPOINT,FSTYPE,TYPE,UUID | egrep -v "^loop"

cp /etc/fstab ~/fstab.bk

## let's add this to the fstab:
UUID=861ebc07-e98a-4c2f-aacd-f9a96bfeac6f       /vol/funmic      auto    defaults        0       2

## works on reboot.
## we may need to change the UUIDs for the student computers when we start them up.

## need the old fashioned zip tools for alfons data?
sudo apt install unzip

## and now get conda going

####### install conda #############
## let's start with miniconda, and put it on the volume:

mkdir -p /vol/funmic/miniconda3

wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh -O /vol/funmic/miniconda3/miniconda.sh
bash /vol/funmic/miniconda3/miniconda.sh -b -u -p /vol/funmic/miniconda3/miniconda3
rm /vol/funmic/miniconda3/miniconda.sh

source /vol/funmic/miniconda3/miniconda3/bin/activate

## add to path env
export PATH=/vol/funmic/miniconda3/miniconda3/bin:$PATH

## initiate with defaults.
conda init

##### metagenome datasets #####

## let's use the mock community data and the kelp dataset, as per last year.

## mock community dataset:

nohup wget ftp://ftp.sra.ebi.ac.uk/vol1/fastq/ERR725/009/ERR7255689/ERR7255689_1.fastq.gz -O /vol/funmic/datasets/ERR7255689_1.fastq.gz &
nohup wget ftp://ftp.sra.ebi.ac.uk/vol1/fastq/ERR725/009/ERR7255689/ERR7255689_2.fastq.gz -O /vol/funmic/datasets/ERR7255689_2.fastq.gz &

## and the kelp dataset. This was tricky last year.

## let's try the SRA toolkit:

## got the binaries here:
wget https://ftp-trace.ncbi.nlm.nih.gov/sra/sdk/current/sratoolkit.current-ubuntu64.tar.gz

tar -xzf sratoolkit.current-ubuntu64.tar.gz

cd /home/ubuntu/sratoolkit.3.1.1-ubuntu64/bin


## set the working directory and temp file location to somewhere on the volume, then 
## seems to work, add to path

export PATH=/home/ubuntu/sratoolkit.3.1.1-ubuntu64/bin:$PATH


## test: 

vdb-config -i

fastq-dump --stdout -X 2 SRR390728

https://www.ncbi.nlm.nih.gov/bioproject/?term=PRJEB36085

## I think we just need the kelp-associated samples, not the water or sediment samples?
## we need SRA run numbers for these, keep clicking till you fun the link for runs.

## I see only 3 non-amplicon files associates with the kelp biofilms.  
## these are:

ERR3801502
ERR3801542
ERR3801603

## saved in 

cd /vol/funmic/datasets/kelpBiofilm

## following this website for 
## https://bioinformaticsworkbook.org/dataAcquisition/fileTransfer/sra.html#gsc.tab=0 

## also these from ncbi:
## https://github.com/ncbi/sra-tools/wiki/08.-prefetch-and-fasterq-dump
## https://github.com/ncbi/sra-tools/wiki/HowTo:-fasterq-dump

/vol/funmic/datasets/kelpBiofilm

## can use old fashioned way:
fastq-dump --split-files --origfmt --gzip ERR3801502

## seems to work, but let's try the prefetch/fasterq combination:

prefetch ERR3801502 
#fasterq-dump --split-spot ERR3801502  ## but this is interleaved. 
fasterq-dump --split-files ERR3801502  ## this seems to works better.

## so a script for this would be:

####### getKelpReads.sh ############
names=(
"ERR3801502"
"ERR3801542"
"ERR3801603"
)

for i in ${names[@]}; do
  prefetch $i
  fasterq-dump --split-files $i
done
####################################

nohup bash getKelpReads.sh &

## looks like it worked. 

########### software installs ###########

## first, is conda using the mamba solver?

conda update -n base conda
conda install -n base conda-libmamba-solver
conda config --set solver libmamba

## get bioconda and conda forge

conda config --add channels defaults
conda config --add channels bioconda
conda config --add channels conda-forge

## let's try to keep our environments in line with the boxes 
## in the overal schematic of the class.

## The first is "quality control of raw sequences". So, let's call it "qualityControlRawSequences"

## the installation of trim-galore should be all we need, this includes fastqc:

conda create -n qualityControlRawSequences -c bioconda trim-galore 
 
## install phyloflash

conda create -n communityComposition -c bioconda phyloflash

## we need a formatted silva database for phyloFlash
cd /vol/funmic/databases

## looks like they haven't updated from last year:
wget https://zenodo.org/record/7892522/files/138.1.tar.gz
mv 138.1/ phyloflashSilvaDB/


tar -xzf 138.1.tar.gz


######### software tests ############

### trim-galore: ###

conda activate qualityControlRawSequences 

trim_galore  -help

## let's check it with our new data:

outDir=~/test
file="/vol/funmic/datasets/Barcode2024/raw_reads/M13-07.fastq.gz"
fastqc -t 10 \
  -o $outDir \
  $file 

getFile=/home/ubuntu/test
putDir=/home/daniel/Documents/teaching/funmic/scratchpad
scp -i /home/daniel/.ssh -P 30423 -r ubuntu@129.70.51.6:$getFile $putDir

## fastqc works

## does the cut-adapt side work?
sipRawReads="/vol/funmic/datasets/Barcode2024/raw_reads"
output=/home/ubuntu/test
## run it
trim_galore \
  --cores 7 \
  -o $output \
  --clip_R1 20 \
  --illumina \
  --length 200 \
  ${sipRawReads}/*fastq.gz

## looks good. 

### phyloflash: ###

conda activate communityComposition

phyloFlash.pl -check_env

phyloFlash.pl -dbhome /vol/funmic/databases/phyloflashSilvaDB -lib TEST -CPUs 14 \
 -read1 ${CONDA_PREFIX}/lib/phyloFlash/test_files/test_F.fq.gz \
 -read2 ${CONDA_PREFIX}/lib/phyloFlash/test_files/test_R.fq.gz \
 -almosteverything

## seems to work
