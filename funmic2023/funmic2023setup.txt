## okay, time to start setting up the 2023 funmic class

## mounting hard drive

## find it:
lsblk

## get uuid
blkid
## mount

sudo mount -U "c1feef14-014f-4cb0-9ee0-4db329308eab" /vol/danBot

## or
sudo mount /dev/vdc /vol/danBot


## to make sure everything is kosher for github:
find . -type f -size +40M

## also, conda broke when we updated a cloud config file.

## reinstall:

wget https://repo.anaconda.com/archive/Anaconda3-2022.10-Linux-x86_64.sh

bash ./Anaconda3-2022.10-Linux-x86_64.sh

## put anaconda here:
/vol/testNotSoBig/anaconda

## first steps, today:

## 0 - clean out the old folders, github repo
## done
## 1 - setup the instance for development
## instance initiated, I think? Not showing on my dashboard...

## 2 - get data sets

## maybe let's check out the Sereika/Albertson data and pipeline:
https://www.nature.com/articles/s41592-022-01539-7#data-availability

## their repo is here:
https://github.com/Serka-M/Digester-MultiSequencing

## their pipeline is really similar to the one we used last year,
## though no biobakery tools were used, just gtdb-tk. 

## I like the biobakery tools, let's decide when we get there...

## they have both mock and environmental data

## the mock DNA is from the zymogen mock community. 
## the eDNA is from activated sludge from an anaerobic sewage
## treatment plant. I don't really understand, because I
## thought "activated" implied the injection of oxygen
## into sewage material...
## intentionally anaerobic conditions implies they wanted
## methane production.
## not sure. Anyway...

## They have illumina reads, pacbio, and nanopore sequence data
## The nanopore data is of two flowcell generations, R10.4 and R9.4.1

## data for the mock community are here:
https://www.ebi.ac.uk/ena/browser/view/PRJEB48692

## in both cases, there are two nanopore platforms on there...
## do we want their minion data?

## quote: 
## "Anaerobic digester and Zymo R.9.4.1 datasets were generated on a MinION Mk1B (Oxford Nanopore Technologies) device"

## so we want the minion datasets

## in the case of the zymo data, I think the nanopore would be:
## sample name = SAMEA10644976 , library name = LIB-Zymo_HMW_R941 
## found here:
https://www.ebi.ac.uk/ena/browser/view/ERR7255742

## note there are promethion data for the R10.4 in the next entry, 

## 
## we won't use the promethion R10.4 data

## I think we are going to need a way to do this without a gui...

## for instance, does this work for the Nanopore Zymo data?

wget ftp://ftp.sra.ebi.ac.uk/vol1/fastq/ERR725/002/ERR7255742/ERR7255742.fastq.gz
## looks like it works...so theoretically these are the files we
## need:

## zymo files (illumina miseq F+R, Nanopore minion):
wget ftp://ftp.sra.ebi.ac.uk/vol1/fastq/ERR725/009/ERR7255689/ERR7255689_1.fastq.gz
wget ftp://ftp.sra.ebi.ac.uk/vol1/fastq/ERR725/009/ERR7255689/ERR7255689_2.fastq.gz
wget ftp://ftp.sra.ebi.ac.uk/vol1/fastq/ERR725/002/ERR7255742/ERR7255742.fastq.gz


## biodigestor files (illumina miseq F+R, Nanopore minion):
## here they have two minion runs. One seems to be for a R10.3 cell.
## So again, stick with the R9.4.1 cell..
## also, there are two sets of illumina miseq files, one set from 2018,
## and one from 2020. The 2020 set doesn't have a finished "generated" fastq
## from the ENA folks. Supp. table 4 seems important here...

wget ftp://ftp.sra.ebi.ac.uk/vol1/fastq/ERR701/006/ERR7014876/ERR7014876.fastq.gz
wget ftp://ftp.sra.ebi.ac.uk/vol1/run/ERR701/ERR7015307/IL-202001-1.fastq.gz
wget ftp://ftp.sra.ebi.ac.uk/vol1/run/ERR701/ERR7015307/IL-202001-2.fastq.gz

## can't find any further data. These last two are the submitted 2020 miseq 
## files, maybe they will work, if not try the 2018 files

## data for the digester are here:
https://www.ebi.ac.uk/ena/browser/view/PRJEB48021

## let's use the R9.4.1 data for the nanopore data
## this is the one that benefitted from polishing 
## with illumina data

## We'll try assembly with illumina alone, nanopore alone, and then 
## nanopore polished by illumina

## weird, though, they used 9 years of illumina data to 
## assist binning...hmm... wonder if we can skip that in the class.

## run through these for the zymogen together, then set them loose on
## the bioreactor data

## they don't have fast5 files, I don't think...
## should we practise basecalling with another dataset?

## tomorrow, start running through the datasets.
## this paper is a bit misleading. The title should actually say something
## like "Near perfect nanopore MAGs without illumina polishing, but with nine years
## of illumina data to help binning"....

## oh well. Let's see how we do. If we have to, go back to mbarc and chu. 


##### set up VM #####

## de.NBI big VM is not working, everytime I try to set up a full, GPU+ 128g RAM, 28 core
## machine, it stalls out.

## So I started up a smaller machine, no GPU, 64g, 28 cores. 

## seems to be running. Do I need to give it a new key?
## they have some on file for me...

ssh -vp 30481  -i /home/daniel/.ssh/ubuntu_e ubuntu@129.70.51.6

## looks like I deleted this key?

grep -R "3NAYJHfS2K3z5DrOM"

## yup. Can we sync up the keys that we used in the spruce project?
## that also seems to not be working...

## let's start over. We are not storing keys on the nanocomp,
## the only old key we need is the one for the emic instance
## that zhe is using.
## also github...

## it looks like our "ubuntu" keys are neither...
## take a chance and delete them.

## can we still use githhub?...yes
## emikAdmin? nope. Just killed it. 

## fix:
chmod 600 ubuntu_e

## plain old emik? yeah, still works

## okay, so those keys are only good for emik stuff.
## can we use our old id_ed keys? I think these are 
## what we use for github...

## so let's make some new ones...

man ssh-keygen

ssh-keygen -f funmic2023 

chmod 600 funmic2023

ssh -p 30427  -i /home/daniel/.ssh/funmic2023 ubuntu@129.70.51.6

## okay, that works. remember not to change keys anymore.
## de.nbi won't update the keys on VMs - they are stuck with 
## the original user-profile public keys when the VM is started

## great, now get our data:

cd /vol/testNotSoBig


sudo chown ubuntu: /vol/testNotSoBig

mkdir datasets

mkdir zymoMC

cd /vol/testNotSoBig/zymoMC
## zymo files (illumina miseq F+R, Nanopore minion):
wget ftp://ftp.sra.ebi.ac.uk/vol1/fastq/ERR725/009/ERR7255689/ERR7255689_1.fastq.gz
wget ftp://ftp.sra.ebi.ac.uk/vol1/fastq/ERR725/009/ERR7255689/ERR7255689_2.fastq.gz
wget ftp://ftp.sra.ebi.ac.uk/vol1/fastq/ERR725/002/ERR7255742/ERR7255742.fastq.gz

cd /vol/testNotSoBig
mkdir sludge

cd /vol/testNotSoBig/sludge
wget ftp://ftp.sra.ebi.ac.uk/vol1/fastq/ERR701/006/ERR7014876/ERR7014876.fastq.gz &
wget ftp://ftp.sra.ebi.ac.uk/vol1/run/ERR701/ERR7015307/IL-202001-1.fastq.gz &
wget ftp://ftp.sra.ebi.ac.uk/vol1/run/ERR701/ERR7015307/IL-202001-2.fastq.gz &

## next step check out the reads:

## everyone, including the authors of this paper, used porechop
## which is pretty much dead. 

## this package was pretty 

## for the illumina reads, we just use old fashioned fastqc

## which means we need to get anaconda going... 

wget https://repo.anaconda.com/archive/Anaconda3-2022.10-Linux-x86_64.sh

## installed

#### set up conda packages ###

## add bioconda
conda config --add channels defaults
conda config --add channels bioconda
conda config --add channels conda-forge
conda config --set channel_priority strict

## for updates
conda update -n base -c defaults conda

## readQC
conda create -n readQC_env -c bioconda cutadapt fastqc bbmap seqtk

### vsearch ###
conda create -n vsearch -c bioconda vsearch

### nanoplot/nanostat ###
## got to relax things a bit
conda config --set channel_priority flexible
conda create -n nanoplot -c bioconda nanoplot
conda config --set channel_priority strict

### megahit ###
conda create -n megahit -c bioconda megahit

### Flye ###
conda create -n flye -c bioconda flye

### check out the zymo data: ###

cd /vol/testNotSoBig/datasets/zymoMC

mkdir /vol/testNotSoBig/datasets/zymoMC/illumina
mkdir /vol/testNotSoBig/datasets/zymoMC/nanopore

gunzip ERR7255689_1.fastq.gz &
gunzip ERR7255689_2.fastq.gz &
gunzip ERR7255742.fastq.gz &

## the 1+2 files probably = illumina

cd /vol/testNotSoBig/datasets/zymoMC/illumina

head ERR7255689_1.fastq

tail ERR7255689_1.fastq

grep "10003:13052/" ERR7255689_1.fastq

grep "10003:13052/" ERR7255689_2.fastq

seq="GGTGACCACTCGCCCGCCCGCCGCGTTCTCTTCGCTCACGGCCAGGGCGAACATGTTAATCCAGTCGATGACGTTCATCGGATCGCGGGAGAGATTATCGCTGGAGACCAGCAGACGCCGTAACGCTACCGCGCGGCGTGGAACGTTCAGC"
seq="TTTGCATCAAAAGAAGCCCTATTTTTAGAAGTTTATCAAGATAGTATTCAGATGGAATTAACAGAACTAGGGAAAGTAGCAGAGCGAGATGATTTGGTTGGGGAAAAGAAGCTACAATCTATTTTCTTTGTAGCGACAGATTTTTCTAGCA"
seq="ACAATGCGATCAATAATGATTTCAATAGAATGCTTTTTATTCTTCTCGATTTCAATTTCGTCATTGATATCATAAATTTCTCCATCAACACGAATTCGAACATAGCCTTCTTTTTTTATTTCCTCAATAGTTTTCTTATGGGTTCCTTTTT"

echo $seq | wc -c ## seems like they are all 152 bp long. 

## why are these sequences so short, if they are miseq?

## seq numbers line up:
head ERR7255689_1.fastq 
head ERR7255689_2.fastq 

tail ERR7255689_1.fastq 
tail ERR7255689_2.fastq 

## these are really short. Did they already do some sort of trimming on them?
## fastqc

conda activate readQC_env

cd /vol/testNotSoBig/datasets/zymoMC/zymoQC

fastqc -o /vol/testNotSoBig/datasets/zymoMC/zymoQC/ \
    /vol/testNotSoBig/datasets/zymoMC/illumina/ERR7255689_*

scp -i /home/daniel/.ssh/funmic2023 -P 30427 \
    ubuntu@129.70.51.6:/vol/testNotSoBig/datasets/zymoMC/zymoQC/ERR7255689_1_fastqc.html .

(firefox ERR7255689_1_fastqc.html &) &

scp -i /home/daniel/.ssh/funmic2023 -P 30427 \
    ubuntu@129.70.51.6:/vol/testNotSoBig/datasets/zymoMC/zymoQC/ERR7255689_2_fastqc.html .

(firefox ERR7255689_2_fastqc.html &) &

## these look very good. A few illumina adapters in there...

## can these be aligned if they are so short?

conda activate readQC_env

## and the big one probably nanopore:
cd /vol/testNotSoBig/datasets/zymoMC/nanopore/

head ERR7255689_1.fastq

tail -n 200 ERR7255742.fastq | less

## how many reads?
grep -c ^@ ERR7255689_1.fastq ## 24887493
## 24,887,493 reads... interesting. let's see how many mags we 
## get out of that...

## how do we find which is the forward? reverse?
## meh, who cares. With so little overlap,
## seems best to just use them unpaired. 

conda activate vsearch 

vsearch --fastq_mergepairs ERR7255689_1.fastq --reverse ERR7255689_2.fastq --threads 20 --fastqout ERR7255689_paired.fasta 

## what does that look like?

conda activate readQC_env

fastqc -o /vol/testNotSoBig/datasets/zymoMC/zymoQC/ \
    /vol/testNotSoBig/datasets/zymoMC/illumina/ERR7255689_paired.fasta

file=/vol/testNotSoBig/datasets/zymoMC/zymoQC/ERR7255689_paired.fasta_fastqc.html

scp -i /home/daniel/.ssh/funmic2023 -P 30427 \
    ubuntu@129.70.51.6:$file .

(firefox ERR7255689_paired.fasta_fastqc.html &) &

head ERR7255689_paired.fasta

## only 8 million reads successfully merged? I think we have to not merge...
## the qualities of both R1 and R2 are high, can we use them without 
## merging?

## let's do it, for now. 

## how about visualizing the nanopore reads?

## we don't have a read report for the nanopore reads, so don't 
## think we can use minionQC.

## so just run fastqc again...

cd /vol/testNotSoBig/datasets/zymoMC/nanopore/

conda activate readQC_env

fastqc -t 20 -o /vol/testNotSoBig/datasets/zymoMC/zymoQC/ \
    /vol/testNotSoBig/datasets/zymoMC/nanopore/ERR7255742.fastq 

## meh, looking like that wants to crash. 
## anyway, it will take forever. Does nohup work?

nohup fastqc -t 20 -o /vol/testNotSoBig/datasets/zymoMC/zymoQC/ \
    /vol/testNotSoBig/datasets/zymoMC/nanopore/ERR7255742.fastq 

file=/vol/testNotSoBig/datasets/zymoMC/zymoQC/ERR7255742_fastqc.html
scp -i /home/daniel/.ssh/funmic2023 -P 30427 \
    ubuntu@129.70.51.6:$file .

(firefox ERR7255689_paired.fasta_fastqc.html &) &

## finding mention of nanoplot and nanostat
## what are these?


## before we go, see if we can get a quick output from nanoplot:

conda activate nanoplot

cd /vol/testNotSoBig/datasets/zymoMC/zymoQC/nanoplotOut

inFastq="/vol/testNotSoBig/datasets/zymoMC/nanopore/ERR7255742.fastq"
outDir="/vol/testNotSoBig/datasets/zymoMC/zymoQC/nanoplotOut/"

nohup NanoPlot -t 6 --verbose --store --huge -o $outDir --fastq $inFastq --format 'png' &

## maybe next time don't save the pickle, too big for github

## check it out:

tar -zcvf nanoplot.tar.gz /vol/testNotSoBig/datasets/zymoMC/zymoQC/nanoplotOut/

file=/vol/testNotSoBig/datasets/zymoMC/nanoplot.tar.gz
scp -i /home/daniel/.ssh/funmic2023 -P 30427 \
    ubuntu@129.70.51.6:$file .

## looks like we need to chop the adapters. Does porechop still work?

## for the barcode data I used cutadapt, previously. 

## tomorrow - do we need to chop adapters? try pore chop, and/or NanoFilt,  and/or cutadapt

## for now, since this is just teaching, let's use cutadapt.

conda activate readQC_env

cd /vol/testNotSoBig/datasets/zymoMC/nanopore/

## the simplest thing is to cut the first nine bp off these.

############################################################################
## debug time
## we know that cutadapt introduces empty reads some where in our pipe
conda deactivate
conda activate readQC_env
head -n 1000000 "/vol/testNotSoBig/datasets/zymoMC/nanopore/ERR7255742.fastq" > npHead.fastq
cutadapt -o ZymoNP_trimmed.fastq --cores 20 --cut 9 npHead.fastq 
grep "^$" npHead.fastq
cutadapt -o ZymoNP_trimmed_filteredEnds.fastq --cores 20 --cut 9 ZymoNP_trimmed.fastq
grep "^$" npHead.fastq

## not found? so where did the empty reads come from?


conda deactivate
conda activate flye

reads=ZymoNP_trimmed_filteredEnds.fastq
flye --meta \
     --threads 25 \
     --out-dir . \
     --nano-hq $reads 

## seems fine. no errors. Why did earlier clipping cause empties?
############################################################################

conda deactivate
conda activate readQC_env

cd /vol/testNotSoBig/datasets/zymoMC/nanopore/

npData="/vol/testNotSoBig/datasets/zymoMC/nanopore/ERR7255742.fastq"
nohup cutadapt -o ZymoNP_trimmed.fastq --cores 25 --cut 9 $npData 

grep "^$" ZymoNP_trimmed.fastq ## check for empties


grep "^$" ZymoNP_trimmed_filteredEnds.fastq ## check for empties

## does flye like it?
conda deactivate
conda activate flye
reads=ZymoNP_trimmed.fastq
flye --meta \
     --threads 25 \
     --out-dir . \
     --nano-hq $reads 
## seems okay

conda deactivate
conda activate readQC_env

## cutadapt can also remove low quality ends, try this, also 

nohup cutadapt -q 10 \
  -o ZymoNP_trimmed_filteredEnds.fastq \
  --cores 25 \
  ZymoNP_trimmed.fastq &

grep -B 2 -A 2 "^$" ZymoNP_trimmed_filteredEnds.fastq ## check for empties
## there they are

conda deactivate
conda activate flye
reads=ZymoNP_trimmed_filteredEnds.fastq
flye --meta \
     --threads 25 \
     --out-dir . \
     --nano-hq $reads 

## yup. 
## fuck it, let's keep the "ragged edges".

## run fastqc on both
file=ZymoNP_trimmed.fastq
fastqc -t 10 \
  -o /vol/testNotSoBig/datasets/zymoMC/ \
  $file &> fastqcNPtrimmedLog.txt &


file=ZymoNP_trimmed_filteredEnds.fastq
fastqc -t 15 \
  -o /vol/testNotSoBig/datasets/zymoMC/ \
  $file &> fastqcNPtrimmedFilteredLog.txt &

## get them

file=/vol/testNotSoBig/datasets/zymoMC/zymoQC/nanopore/ZymoNP_trimmed_fastqc.html
scp -i /home/daniel/.ssh/funmic2023 -P 30427 \
    ubuntu@129.70.51.6:$file .

file=/vol/testNotSoBig/datasets/zymoMC/ZymoNP_trimmed_filteredEnds_fastqc.html
scp -i /home/daniel/.ssh/funmic2023 -P 30427 \
    ubuntu@129.70.51.6:$file .

(firefox ZymoNP_trimmed_fastqc.html &) &

(firefox ZymoNP_trimmed_filteredEnds_fastqc.html &) &

find . ZymoNP_trimmed_filteredEnds.fastq_fastqc.html

## that takes a long time, the fastqc generation.
## but both steps really helped. 

## just do fastqc once before on primary inspection of the nanopore reads
## and once after trimming and filtering.

## actually, just trimming. Filtering is screwing up our fasta 

## the illumina data seems find to me, except it doesn't pair well.
## can we still use it for assembly

### run assemblers! ###

## for the nanopore data, we'll use metaFlye 

## https://github.com/fenderglass/Flye

## for the illumina, we can choose between megahit and spades..

## both we (last year) and the Sereika project use megahit, so let's 
## stay with it.

conda activate megahit

megahit -1 pe_1.fq -2 pe_2.fq -o out
megahit -r $MBARCreads -o megahITmbaRCOut

\time -v megahit -1 ERR7255689_1.fastq \
          -2 ERR7255689_2.fastq \
          -t 25 \
          -o megahitZymoIllumina &> megahit.log &

## moved to:

## not sure how well it went, but let's 
## that was really quick - N50 is 103233, not bad

## try to start the flye assembler, might take longer...

conda activate flye

ls /vol/testNotSoBig/datasets/zymoMC/nanopore/

cd /vol/testNotSoBig/assemblies/zymoMC/flyeNanopore/

#reads=/vol/testNotSoBig/datasets/zymoMC/nanopore/ZymoNP_trimmed_filteredEnds.fastq

reads=/vol/testNotSoBig/datasets/zymoMC/nanopore/ZymoNP_trimmed.fastq
outdir=/vol/testNotSoBig/assemblies/zymoMC/flyeNanopore/
\time -v nohup flye --meta \
          --threads 25 \
          --out-dir $outdir \
          --nano-hq $reads &> howlongDidIflye.log &

## oh crap. ran out of memory. Time to start a fat node.

##file=/vol/testNotSoBig/datasets/zymoMC/nanopore/ERR7255742.fastq
file=/vol/testNotSoBig/datasets/zymoMC/nanopore/ZymoNP_trimmed_filteredEnds.fastq

grep -B 6 -A 2 "@ERR7255742.1631 " $file

## are there others?
head -n 10000 $file | grep -B 2 -A 2 "^$"

## find these errors using empty lines
## can't acutally look for linbreaks with grep
grep -n -B 2 -A 2 "^$" $file > empties.txt &

grep -n -B 2 -A 2 "^$" $file ## not found when we look in the pre-cutadapt

## yeah, looks like a lot of empty reads after 

## just curious, do we get the same result from the raw file?
reads=/vol/testNotSoBig/datasets/zymoMC/nanopore/ZymoNP_trimmed_filteredEnds.fastq

### check out the sludge data ### 

cd /vol/testNotSoBig/datasets/sludge

gunzip IL-202001-1.fastq.gz &
gunzip IL-202001-2.fastq.gz &
gunzip ERR7014876.fastq.gz &

## sludge illumina

cd /vol/testNotSoBig/datasets/sludge/illumina

head -n 1 IL-202001-1.fastq

tail IL-202001-1.fastq

head -n 1 IL-202001-2.fastq

tail IL-202001-2.fastq

## why are these different?
tail -n 4 IL-202001-1.fastq | head -n 1
tail -n 4 IL-202001-2.fastq | head -n 1

## these do not look like paired read files to me

head -n 1000 IL-202001-1.fastq | less

## for instance:
grep -A 2 "16026:1992" IL-202001-1.fastq ## gives us:
@M00878:365:000000000-CVP5H:1:1102:16026:1992_1
@M00878:365:000000000-CVP5H:1:1102:16026:1992_2
## both in the same file


grep -A 2 "16026:1992" IL-202001-2.fastq ## nothing is found. 

grep -n "1102:16026:1992_" IL-202001-1.fastq &> findreadpairplace.txt ## gives us:
997:@M00878:365:000000000-CVP5H:1:1102:16026:1992_1
47092901:@M00878:365:000000000-CVP5H:1:1102:16026:1992_2

## how many reads are there?

grep -c ^@M00 IL-202001-1.fastq &> zoop ## 23545952 23,545,952

grep -c ^@M00 IL-202001-2.fastq &> zoop ## 23545952 23,545,952

## ugh, this is a fucking nature paper and I still have to clean
## data. 

tail IL-202001-1.fastq 

head -n 1000 IL-202001-2.fastq | less

## so looks like paired reads, but each file contains its own paired data?

## then why are they the exact same number of reads? That is weird.

## good explanation on illumina fastq sequence identifiers here: 
## https://support.illumina.com/help/BaseSpace_OLH_009008/Content/Source/Informatics/BS/FileFormat_FASTQ-files_swBS.htm

seq="CCCATTGCTTTTCATCACTTCAATTGTGTACCTTTGCTCTACGGTTAAATGGCTCATATTTTGCAACTTTTGGACGAGGACACAAAGTAAAGAGAATTTATCCATTTCAGGCGGGGGGACATTTTTGTCCCTTCGCTTGAAAAAAATTAATTCATGCCCTCAAAAAGTTGCATTTATTAGTT"
echo $seq | wc -c ## 183 BP, still short for miseq

## so if these are not paired, what are we looking at? 

## goals - fastqc all illumina, 

###### start over on new instance ####

## denbi has come through with the heavier (128 gb ram), GPU-equipped VMs.
## also, our medium instance (64gb) can't handle the full nanopore dataset
## assembly. So time to try the big guns.

## ssh for new instance:

ssh -p 30500 -i /home/daniel/.ssh/ubuntu_e ubuntu@129.70.51.6

## or just

danBot

## get anaconda on there:
wget https://repo.anaconda.com/archive/Anaconda3-2022.10-Linux-x86_64.sh

bash ./Anaconda3-2022.10-Linux-x86_64.sh

/vol/danBot/

## let's make it so danbot and funcomp can talk.

## on danbot, make a keypair:
ssh-keygen -f danbotFuncomp

chmod 600 danbotFuncomp
chmod 444 danbotFuncomp.pub

## put the pub key on funcomp authorized_keys
cat danbotFuncomp.pub

## try login:
ssh -vp 30427  -i /home/ubuntu/.ssh/danbotFuncomp ubuntu@129.70.51.6
## works

## what do we need?
## the raw data, get it all:

file=/vol/testNotSoBig/datasets/
nohup scp -i /home/ubuntu/.ssh/danbotFuncomp -P 30427 -r ubuntu@129.70.51.6:$file . &

## meh, something failed.
## in the end, detach old volume and attach here. 
## let's try our flye assembly again:

conda activate flye

reads=/vol/danBot/datasets/zymoMC/nanopore/ZymoNP_trimmed.fastq
outdir=/vol/danBot/assemblies/zymoMC/flyeNanopore/
\time -v nohup flye --meta \
          --threads 25 \
          --out-dir $outdir \
          --nano-hq $reads &> howlongDidIflye.log &

## anything else we can do right now?

## could get started on binning...
