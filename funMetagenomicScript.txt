#### here we will keep our script of our metagenomic project ####

## let's look at our mock community reads with fastqc  

## first we have to log in again to your de.NBI machine with ssh

## your login info is in the funBASHterminalScript.txt

## that script is at https://github.com/danchurch/FunctionalMicrobiomePractical2022

## you can download it by going to 

## https://github.com/danchurch/FunctionalMicrobiomePractical2022/blob/main/funBASHterminalScript.txt

## and right-clicking on "Raw" and saving it.
## this is my key, that I use for logins
pathToKey=/home/daniel/.ssh/denbiTestVM
ssh -p 30009 -i $pathToKey ubuntu@129.70.51.6
## your port will be different, I think this is Kai's de.NBI machine

## now that you are on your machine...

#### quality control of reads #### 

## activate conda
conda env list 

conda activate readQC_env

## your reads for the mock community should be here:
cd /vol/studentFunMic1Vol/sequenceData/mbarc

## look at the file - how big is it?
ls -lh smallerMBARC_trimmed.fq

## what does a fastq file look like in real life?:
head smallerMBARC_trimmed.fq

## let's run fastqc to get a quality report
## -o tells fastqc where to put its output 
## --threads 8 tells fastqc to use 8 processors  

fastqc -o /home/ubuntu/danFastQCout --threads 8 smallerMBARC_trimmed.fq

## let's get the file from de.NBI to our local computers, with scp

pathToKey=/home/daniel/.ssh/denbiTestVM

scp -P 30009 -i $pathToKey \
ubuntu@129.70.51.6:/home/ubuntu/danFastQCout/smallerMBARC_trimmed_fastqc.html .
 
## put this somewhere where both windows and linux can read it:

cp smallerMBARC_trimmed_fastqc.html /mnt/c/PUTLINUXFILESHERE/

######### start assembly ############

## let's start the job of making an assembly with megahit

conda env list

conda activate assembly_env

MBARCreads=/vol/studentFunMic1Vol/sequenceData/mbarc/smallerMBARC_trimmed.fq

megahit -r $MBARCreads -o ~/megahitMBARCOut -t 8

## this will run for a while!


######### check assembly with metaquast #############

## let's run a quick check on our assembly with metaquast

## get on your denbi machine, your port and key will be different

pathToKey=~/.ssh/denbiTestVM
ssh -p 30112 -i $pathToKey ubuntu@129.70.51.6

## remember that for us, most of the interesting files are here:
cd /vol/studentFunMic1Vol

## activate the correct conda environment 
conda activate quast_env

## where is our assembly from megahit?

## it will be where you asked megahit to build its output directory above

## if you can't find it, this might work:

## the find command!!!

find . -name "final.contigs.fa"

## once you find it, look around in that directory. What do you see?

## make a working directory for metaquast

mkdir -p /vol/studentFunMic1Vol/metaquast/mbarc

cd /vol/studentFunMic1Vol/metaquast/mbarc

## now run metaquast on your reads

pathToAssembly="/vol/studentFunMic1Vol/final.contigs.fa" ## yours will be different!
metaquast --threads 6 $pathToAssembly 

## metaquast ships with some visualizations... 

## remember the process of getting files into windows from de.NBI?

## leave de.NBI 
logout

## my quast outputs are here, set a variable to there
quastOutputs=/vol/studentFunMic1Vol/metaquast/mbarc/quast_results
## use scp to get the file, as usual your port and key will be different
pathToKey=~/.ssh/denbiTestVM

## get the directory! note that we have to use "-r" option, because it is a folder
scp -r -P 30112 -i $pathToKey ubuntu@129.70.51.6:$quastOutputs .

mv quastResults/ /mnt/c/PUTLINUXFILESHERE/

cp -r quastResults/ /mnt/c/PUTLINUXFILESHERE/

## this has numerous icarus and krona charts, with comparisons to established 
## genomes that blasted close the 16s sequences that were extracted from our 
## assembly. Let's look through them!


#### metaphlan ####

conda env list

conda activate metaphlan_env

metaphlanMarkerDB=/vol/studentFunMic1Vol/metaphlanMarkerDB
MBARCraw=/vol/studentFunMic1Vol/sequenceData/mbarc/smallerMBARC_trimmed.fq

mkdir -p /vol/studentFunMic1Vol/metaphlanWD/mbarcMPA
cd /vol/studentFunMic1Vol/metaphlanWD/mbarcMPA

metaphlan $MBARCraw \
    --bowtie2db $metaphlanMarkerDB \
    --nproc 6 \
    --input_type fastq \
    -o mbarcMetaPhlanProfiled_metagenome.txt \


find . -name mbarcMetaPhlanProfiled_metagenome.txt

## this should have produced a single text file, mine is here:

cd /vol/studentFunMic1Vol/metaphlanWD/mbarcMPA

## let's look at it:

less mbarcMetaPhlanProfiled_metagenome.txt

## that's a lot. Let's look at the lowest level, let's do some BASH magic on it:

grep -E "s__|clade" mbarcMetaPhlanProfiled_metagenome.txt | sed 's/^.*s__//g' | cut -f1,3 > mbarcMetaPhlanAbundances.tsv

grep -E "s__|clade" mbarcMetaPhlanProfiled_metagenome.txt | \
sed 's/^.*s__//g' | \

wc -l mbarcMetaPhlanAbundances.tsv

cut -f1,3 > mbarcMetaPhlanAbundances.tsv


## you can look at that with your de.NBI machine using less, or you can 
## get it locally with the usual methods, maybe to make some nice graphs. 

## how do these abundances compare to metaquast, and to the paper itself 

## are there any differences? Why would they be different?

######### binning ###############

## time to bin our contigs from our assembly into possible genomes

## we'll try three different binning software, concoct, MetaBAT2, and Maxbin

## some of these binning algorithms require that we align our raw reads
## back onto the assembly, to get an idea of relative abundances. 

##### aligning raw reads to our assembly #####

## use bowtie for this:
conda activate alignment_env

mkdir -p /vol/studentFunMic1Vol/mbarcAligned2assembly/

rawReads=/vol/studentFunMic1Vol/sequenceData/mbarc/smallerMBARC_trimmed.fq 
readsAligned2assembly=/vol/studentFunMic1Vol/mbarcAligned2assembly/
assembly="/vol/studentFunMic1Vol/final.contigs.fa"

cd /vol/studentFunMic1Vol/
find . -name "final.contigs.fa"

## we need to build an index
bowtie2-build --threads 8 $assembly $readsAligned2assembly/mbarcAssemblyIndex 

## now use this index to make our alignment:
cd $readsAligned2assembly

bowtie2 -x $readsAligned2assembly/mbarcAssemblyIndex \
    -U $rawReads \
    --threads 10 \
    -S mbarcReads2Assembly.sam

### I think we need to sort these?

cd $readsAligned2assembly

samtools sort -@7 -o mbarcAlignedSorted.bam -O BAM mbarcReads2Assembly.sam 

## and index them 
samtools index -@7 mbarcAlignedSorted.bam 

## these should be ready for our binning software

##### concoct ######

## first binner is concoct

conda activate concoct_env

assembly="/vol/studentFunMic1Vol/final.contigs.fa" ## your path will probably be different
mbarcAlignedSorted=/vol/studentFunMic1Vol/mbarcAligned2assembly/mbarcAlignedSorted.bam

mkdir /vol/studentFunMic1Vol/concoctWD

cd /vol/studentFunMic1Vol/concoctWD

##1
cut_up_fasta.py $assembly -c 10000 -o 0 --merge_last -b mbarcConcoctContigs_10K.bed > mbarcConcoctContigs_10K.fa

##2
concoct_coverage_table.py mbarcConcoctContigs_10K.bed $mbarcAlignedSorted > mbarcConcoctCoverage_table.tsv

## 3
concoct \
  --composition_file mbarcConcoctContigs_10K.fa \
  --coverage_file mbarcConcoctCoverage_table.tsv \
  -t 7 \
  -b concoct_output/ 

## 4

merge_cutup_clustering.py \
  concoct_output/clustering_gt1000.csv > concoct_output/clustering_merged.csv

## 5
mkdir concoct_output/fasta_bins

extract_fasta_bins.py $assembly concoct_output/clustering_merged.csv --output_path concoct_output/fasta_bins



####### metabat #########

conda activate metabat2_env

mkdir /vol/studentFunMic1Vol/metabat2WD

cd /vol/studentFunMic1Vol/metabat2WD

## influent metabat2 binning:

assembly="/vol/studentFunMic1Vol/final.contigs.fa" ## your path will probably be different
mbarcAlignedSorted=/vol/studentFunMic1Vol/mbarcAligned2assembly/mbarcAlignedSorted.bam

runMetaBat.sh $assembly $mbarcAlignedSorted

## I didn't change threads, check out help file 


########### maxbin2 ############

conda activate maxbin2_env

mkdir /vol/studentFunMic1Vol/maxbin2WD

cd /vol/studentFunMic1Vol/maxbin2WD

assembly="/vol/studentFunMic1Vol/final.contigs.fa" ## your path will probably be different
rawReads=/vol/studentFunMic1Vol/sequenceData/mbarc/smallerMBARC_trimmed.fq 

## run with lots of threads!!!:
run_MaxBin.pl -contig $assembly \
    -reads $rawReads \
    -thread 13 \
    -out mbarcMaxBinOut2 







####### DAS tools ##########

conda activate dastool_env

mkdir /vol/studentFunMic1Vol/DAS_tool 

cd /vol/studentFunMic1Vol/DAS_tool 

## we needs a contig(scaffold)-to-bin map for each of our 
## binning softwares

## maxbin contigs/bin 

maxBins=/vol/studentFunMic1Vol/maxbin2WD

Fasta_to_Scaffolds2Bin.sh \
    -e fasta \
    -i $maxBins \
        > /vol/studentFunMic1Vol/maxbin2WD/maxbin_scaffolds2bin.tsv





## metabat contigs/bin. The exact name will be different for you!
metabatBins=/vol/studentFunMic1Vol/metabat2WD/final.contigs.fa.metabat-bins-20220310_132455

Fasta_to_Scaffolds2Bin.sh \
    -e fa \
    -i $metabatBins \
        > /vol/studentFunMic1Vol/metabat2WD/metabat_scaffolds2bin.tsv








## concoct contigs/bin. 

concoctBins=/vol/studentFunMic1Vol/concoctWD/concoct_output/fasta_bins

Fasta_to_Scaffolds2Bin.sh \
    -e fa \
    -i $concoctBins \
        > /vol/studentFunMic1Vol/concoctWD/concoct_output/concoct_scaffolds2bin.tsv

## so we have the following 

maxbin_scaffolds2bin=/vol/studentFunMic1Vol/maxbin2WD/maxbin_scaffolds2bin.tsv
metabat_scaffolds2bin=/vol/studentFunMic1Vol/metabat2WD/metabat_scaffolds2bin.tsv
concoct_scaffolds2bin=/vol/studentFunMic1Vol/concoctWD/concoct_output/concoct_scaffolds2bin.tsv

## still need the original assembly, might be in a different place for you! find it
assembly=/vol/studentFunMic1Vol/final.contigs.fa

## get back in your working directory for DAS tools:
cd /vol/studentFunMic1Vol/DAS_tool 

DAS_Tool \
    -i $maxbin_scaffolds2bin,$metabat_scaffolds2bin,$concoct_scaffolds2bin \
    -l maxbin,metabat,concoct \
    -t 10 \
    --search_engine diamond \
    -c $assembly \
    --write_bin_evals 1 \
    --write_bins 1 \
    -o mbarcDASToolRun1 

### you should now have some higher quality bins to work with! 

## (where are they? find them)


####### evaluating potential MAGs with checkM #######

## let's look at our new bins from DAS tool

mkdir /vol/studentFunMic1Vol/checkm/mbarc

cd /vol/studentFunMic1Vol/checkm/mbarc

## checkm influent
conda activate checkm_env

mbarcBins=/vol/studentFunMic1Vol/DAS_tool/mbarcDASToolRun1_DASTool_bins

## let check find where our bins belong in the phylogeny of life!!
checkm lineage_wf -t 10 -x fa $mbarcBins checkmMbarcOut

## this also generated the markers we need to do some quality analyses.
## we can look at this with checkm's qa function:
mbarcMarkers=/vol/studentFunMic1Vol/checkm/mbarc/checkmMbarcOut/lineage.ms

checkm qa $mbarcMarkers checkmMbarcOut 

## let's put these somewhere as a file so we have it for later
checkm qa $mbarcMarkers checkmMbarcOut > /vol/studentFunMic1Vol/checkm/mbarc/checkmMBARCResults.txt

less /vol/studentFunMic1Vol/checkm/mbarc/checkmMBARCResults.txt

## talk about this table with Dan and your other colleagues - can you make sense of it?


######## taxonomy of MAGs with phylophlan ########

## now that we have several metagenome assembled genomes,
## it would be great to get an idea of their taxonomic 
## status - who are these organisms???

conda activate metaphlan_env


mkdir /vol/studentFunMic1Vol/phylophlanWD
cd /vol/studentFunMic1Vol/phylophlanWD

## check out how this command works
phylophlan_metagenomic --help

MAGs=/vol/studentFunMic1Vol/DAS_tool/mbarcDASToolRun1_DASTool_bins 
## that ^ might be different for you!!! do you know where your final bins are right now??

phylophlan_metagenomic \
    -i $MAGs \
    -d SGB.Jul20 \
    -o mbarc_phylophlanOut \
    --nproc 10 \
    -n 1 \
    --verbose 

## if you want to see other closely related genomes, change "-n" option

## let's look at the results:

mbarcPhyl=/vol/studentFunMic1Vol/phylophlanWD/mbarc_phylophlanOut.tsv

less mbarc_phylophlanOut.tsv

## clean it up a little with some BASH string manipulations:

tail -n +2 $mbarcPhyl | sed "s/\t/\n/g" > mbarc_phylophlan_matches.txt

less mbarc_phylophlan_matches.txt

## do you understand this table? What are the numbers??? 



###### metabolic pathways  ########

## let's ship off one of these bins to be annotated by 
## the good folks working on KEGG (Kyoto Encyclopedia of Genes and Genomes)

## the research groups responsible for KEGG have some
## an automated annotation services, we just need to ship
## them a genome with gene predictions, in the form of amino acid sequences

## for this, we use prodigal:


conda activate prodigal_env

mkdir /vol/studentFunMic1Vol/blastkoalaWD
cd /vol/studentFunMic1Vol/blastkoalaWD

## find one by looking at your phylophlan taxonomic data:
less /vol/studentFunMic1Vol/phylophlanWD/mbarc_phylophlan_matches.txt

## I'll take number 41, identified by phylophlan as Natronococcus occultus:

## my final bins are here:
dasToolBins=/vol/studentFunMic1Vol/DAS_tool/mbarcDASToolRun1_DASTool_bins

## if you are still your blastKOALA directory:
cp $dasToolBins/41.fa . 

## predict genes with prodigal:

prodigal \
  -a 41.genes.faa \
  -d 41.genes.fna \
  -f gff \
  -o 41.genes.gff \
  -i 41.fa

## get the amino acid sequences and give this BlastKOALA:

## go local
logout

## get file

pathToKey=~/.ssh/denbiTestVM

scp -i $pathToKey -P 30112 ubuntu@129.70.51.6:/vol/studentFunMic1Vol/blastkoalaWD/41.genes.faa .

## now give that file to:

https://www.kegg.jp/blastkoala/


######## starting on the Chu Data wastewater treatment data #########

## now let's set you loose on some data from an ecological study:

## our data is here:

cd /vol/studentFunMic1Vol/sequenceData/Chu

## let's divide into two groups, one for influent, one for effluent

## the influent group should be small (2 people?), and the effluent group should 
## more (=5 poeple?) 

## what would you do first?


